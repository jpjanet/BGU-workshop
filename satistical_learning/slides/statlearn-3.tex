\begin{align*}
\mathcal{E}(f^{*}) - \mathcal{E}(\hat{f}) &=   \only<1->{\color{red}}\left[\mathcal{E}(f^{*})-\mathcal{E}(f^{\dagger})\right] \only<1->{\color{black}} + \only<1->{\color{blue}}\left[\mathcal{E}(f^{\dagger})-\mathcal{E}(\hat{f})\right]\only<1->{\color{black}}
\end{align*}
Two critical ideas that are worth noting. Under mild assumptions one can show that:
\begin{enumerate}
\uncover<2->{\item with enough data, a sufficiently complicated model with near-zero {\color{red}approximation error} will generalize arbitrarily well. }
\uncover<3->{\item {\color{blue}estimation error} is inversely related to model complexity, i.e. more complicated spaces of models require more data to generalize. }
\end{enumerate}
\only<4>{We want $\mathcal{T}$ to be large/complicated enough to have low approximation error,  \textbf{but no more complicated}.}
\only<5>{ With limited data, we are often better off searching for a model in a simpler family models of that `learn' more robustly and quickly as opposed to very complicated models with lots of parameters.}
\only<6> {Conversely,  a simple model will stop improving with more data past a certain point -- where the approximation error dominates.}