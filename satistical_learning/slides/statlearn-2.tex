We cannot expect that $f^*$ is in $\mathcal{T}$. The best we can do is $f^{\dagger}$:
\begin{align*}
    f^{\dagger}&= \arg \min_{f\in \mathcal{T}}R(f)
\end{align*}

We want to generalize,  we want the \textit{excess risk} to be small:
\begin{align*}
     R(f^{*}) - R_{emp}(\hat{f}) &=   \left[R(f^{*})-R(f^{\dagger})\right] + \left[R(f^{\dagger})-R(\hat{f})\right]
\end{align*}
these terms are \textbf{approximation error} and \textbf{estimation error}. Statistical learning theory is concerned with studying these equations.
